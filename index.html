<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Shuzhao Xie</title>
  
  <meta name="author" content="Shuzhao Xie">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Shuzhao Xie</name>
              </p>
              <p>I am a PhD student at <a href="https://www.sigs.tsinghua.edu.cn">Tsinghua SIGS</a>, 
                working with Prof. <a href ="http://zwang.inflexionlab.org">Zhi Wang</a> on metaverse. 
                I received my Master's degree in Computer Technology from <a href="https://www.tsinghua.edu.cn">Tsinghua University</a> in 2023
                and my Bachelor's degree in Computer Science and Technology from <a href="https://en.wikipedia.org/wiki/Beijing_Normal_University">Beijing Normal University</a> in 2020.
              </p>
              <p style="text-align:center">
                <a href="mailto:xiesz99@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/ShuzhaoXie-CV.pdf">CV [2025.01]</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=_2QNPGYAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/ShuzhaoXie/">Github</a> &nbsp/&nbsp
                <a href="https://calendar.google.com/calendar/u/0?cid=eGllc3o5OUBnbWFpbC5jb20">Calendar</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/ShuzhaoXie_v2.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/ShuzhaoXie_v2.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research Interests</heading>
              <p>
                My research is in the area of robotics, computer vision, and machine learning system. Specifically,            
                I have experience in machine learning services, reinforcement learning, gaussian splatting, and generative models.
              </p>
              <!-- <p>
                My research is in the area of novel view synthesis, generative models, and serving system. 
                I'm interested in designing systems to efficiently utilize deep learning models/services and exploiting deep learning techniques to empower network systems.
                I have experience in machine learning cloud services, reinforcement learning algorithms, and edge hardwares (e.g., Jetson Nano, Raspberry Pi).
              </p> -->
              <!-- <p>
                <span class="highlight">I will graduate in 2023, and am currently looking for a PhD position working on network/system.</span>
              </p> -->
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Publications</heading>
          </td>
        </tr>
      </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <!-- <tr onmouseout="mlaas_stop()" onmouseover="mlaas_start()"> -->
          
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/25-icassp-lungmix.png' width="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="">
                  <papertitle>Lungmix: A Mixup-Based Strategy for Generalization in Respiratory Sound Classification</papertitle>
                </a>
                <br>
                Shijia Ge, 
                Weixiang Zhang,
                <strong>Shuzhao Xie</strong>, 
                Baixu Yan,
                <a href="http://zwang.inflexionlab.org">Zhi Wang</a>
                <br>
                <em>IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</em>, 2025
                <br>
                <a href="./data/25-icassp-lungmix.pdf">paper</a>
                <!-- /
                <a href="https://shuzhaoxie.github.io/mesongs/">project page</a>
                / -->
                <!-- <a href="">video</a> -->
                <!-- / -->
                <!-- <a href="https://github.com/zwx-open/Symmetric-Power-Transformation-INR">code</a> -->
                <!-- <p></p> -->
                <!-- <p>
                Post-training 3D Gaussians Compression. 
                </p> -->
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/25-icassp-pulmoscan.png' width="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="">
                  <papertitle>PulmoScan: A Practical Pulmonary Disease Pre-Screening System</papertitle>
                </a>
                <br>
                Baixu Yan,
                Shijia Ge,
                Meizi Lu,
                Weixiang Zhang, 
                <strong>Shuzhao Xie</strong>, 
                <a href="http://zwang.inflexionlab.org">Zhi Wang</a>
                <br>
                <em>IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</em>, 2025
                <br>
                <a href="./data/25-icassp-pulmoscan.pdf">paper</a>
                <!-- /
                <a href="https://shuzhaoxie.github.io/mesongs/">project page</a>
                / -->
                <!-- <a href="">video</a> -->
                <!-- / -->
                <!-- <a href="https://github.com/zwx-open/Symmetric-Power-Transformation-INR">code</a> -->
                <!-- <p></p> -->
                <!-- <p>
                Post-training 3D Gaussians Compression. 
                </p> -->
              </td>
            </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/25-aaai-sym.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Enhancing Implicit Neural Representations via Symmetric Power Transformation</papertitle>
              </a>
              <br>
              Weixiang Zhang, 
              <strong>Shuzhao Xie</strong>, 
              Chengwei Ren, 
              Shijia Ge, 
              Mingzi Wang, 
              <a href="http://zwang.inflexionlab.org">Zhi Wang</a>
              <br>
              <em>The 39th Annual AAAI Conference on Artificial Intelligence (AAAI)</em>, 2025
              <br>
              <a href="./data/25-aaai-spt.pdf">paper</a>
              <!-- /
              <a href="https://shuzhaoxie.github.io/mesongs/">project page</a>
              / -->
              <!-- <a href="">video</a> -->
              /
              <a href="https://github.com/zwx-open/Symmetric-Power-Transformation-INR">code</a>
              <!-- <p></p> -->
              <!-- <p>
              Post-training 3D Gaussians Compression. 
              </p> -->
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/24-eccv-mesongs.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>MesonGS: Post-training Compression of 3D Gaussians via Efficient Attribute Transformation</papertitle>
              </a>
              <br>
              <strong>Shuzhao Xie</strong>,
              Weixiang Zhang, 
							<a href="https://www.chentang.cc">Chen Tang</a>,
              <a href="https://bbaaii.github.io/">Yunpeng Bai</a>,
              <a href="">Rongwei Lu</a>,
              Shijia Ge,
              <a href="http://zwang.inflexionlab.org">Zhi Wang</a>
              <br>
              <em>European Conference on Computer Vision (ECCV)</em>, 2024
              <br>
              <a href="data/24-eccv-mesongs.pdf">paper</a>
              /
              <a href="https://shuzhaoxie.github.io/mesongs/">project page</a>
              /
              <!-- <a href="">video</a> -->
              <!-- / -->
              <a href="https://github.com/ShuzhaoXie/MesonGS">code</a>
              <p></p>
              <!-- <p>
              Post-training 3D Gaussians Compression. 
              </p> -->
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/2024-tmm-skyml.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>SkyML: A MLaaS Federation Design for Multicloud-based Multimedia Analytics</papertitle>
              </a>
              <br>
              <strong>Shuzhao Xie</strong>,
              Yuan Xue, 
							Yifei Zhu,
              <a href="http://zwang.inflexionlab.org">Zhi Wang</a>
              <br>
              <em>IEEE Transactions on Multimedia (TMM) </em>, 2024
              <br>
              <a href="data/24-tmm-skyml.pdf">paper</a>
              /
              <!-- /
              <a href="https://shuzhaoxie.github.io/mesongs/">project page</a>
              / -->
              <!-- <a href="">video</a> -->
              <!-- / -->
              <a href="https://github.com/ShuzhaoXie/Armol">code</a>
              <p></p>
              <!-- <p>
              Post-training 3D Gaussians Compression. 
              </p> -->
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/24-arxiv-expansion.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Expansive Supervision for Neural Radiance Field</papertitle>
              </a>
              <br>
              Weixiang Zhang, 
              <strong>Shuzhao Xie</strong>,
              Shijia Ge,
              Wei Yao,
							<a href="https://www.chentang.cc">Chen Tang</a>,
              <a href="http://zwang.inflexionlab.org">Zhi Wang</a>
              <br>
              <em>arXiv</em>, 2024
              <br>
              <a href="data/24-arxiv-expansive.pdf">paper</a>
              <!-- / -->
              <!-- <a href="https://shuzhaoxie.github.io/mesongs/">project page</a> -->
              <!-- / -->
              <!-- <a href="">video</a> -->
              <!-- / -->
              <!-- <a href="https://github.com/ShuzhaoXie/MesonGS">code</a> -->
              <p></p>
              <!-- <p>
              Post-training 3D Gaussians Compression. 
              </p> -->
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/24-arxiv-visctrl.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
              <papertitle>Tuning-Free Visual Customization via View Iterative Self-Attention Control</papertitle>
              </a>
              <br>
              Xiaojie Li,
              Chenghao Gu,
              <strong>Shuzhao Xie</strong>,
              <a href="https://bbaaii.github.io/">Yunpeng Bai</a>,
              Weixiang Zhang, 
              <a href="http://zwang.inflexionlab.org">Zhi Wang</a>
              <br>
              <em>arXiv</em>, 2024
              <br>
              <a href="data/24-arxiv-visctrl.pdf">paper</a>
              <!-- /
              <a href="data/24-cvpr-rfquant-supp.pdf">supp</a>
              /
              <a href="data/24-cvpr-rfquant-poster.pdf">poster</a>
              /
              <a href="https://github.com/1hunters/retraining-free-quantization/">code</a> -->
              <p></p>
              <p>
                
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/24-cvpr-rfquant.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
              <papertitle>RFQuant: Retraining-free Model Quantization via One-Shot Weight-Coupling Learning</papertitle>
              </a>
              <br>
              <a href="https://www.chentang.cc">Chen Tang*</a>,
              Yuan Meng*,
              Jiacheng Jiang,
              <strong>Shuzhao Xie</strong>,
              Rongwei Lu, 
              Xinzhu Ma, 
              <a href="http://zwang.inflexionlab.org">Zhi Wang</a>, 
              Wenwu Zhu
              <br>
              <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2024
              <br>
              <a href="data/24-cvpr-rfquant.pdf">paper</a>
              /
              <a href="data/24-cvpr-rfquant-supp.pdf">supp</a>
              /
              <a href="data/24-cvpr-rfquant-poster.pdf">poster</a>
              /
              <a href="https://github.com/1hunters/retraining-free-quantization/">code</a>
              <p></p>
              <p>
                
              </p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/24-europar.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
              <papertitle>A Joint Approach to Local Updating and Gradient Compression for Efficient Asynchronous Federated Learning</papertitle>
              </a>
              <br>
              Jiajun Song,
              Jiajun Luo, 
              Rongwei Lu,
              <strong>Shuzhao Xie</strong>,
              Bin Chen,
              <a href="http://zwang.inflexionlab.org">Zhi Wang</a>, 
              Wenwu Zhu
              <br>
              <em>International European Conference on Parallel and Distributed Computing (Euro-Par)</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2407.05125">paper</a>
              <p></p>
              <p>
                
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/textir.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
              <papertitle>TextIR: A Simple Framework for Text-based Editable Image Restoration</papertitle>
              </a>
              <br>
              <a href="https://bbaaii.github.io/">Yunpeng Bai</a>,
              Cairong Wang,
              <strong>Shuzhao Xie</strong>,
              Chao Dong,
              Chun Yuan,
              <a href="http://zwang.inflexionlab.org">Zhi Wang</a>
              <br>
              <em>arXiv</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2302.14736">paper</a>
              <p></p>
              <p>
                In this work, we design an effective framework that allows the user to control the restoration process of degraded images with text descriptions. We use the text-image feature compatibility of the CLIP to alleviate the difficulty of fusing text and image features. Our framework can be used for various image restoration tasks, including image inpainting, image super-resolution, and image colorization.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/22-infocom-armol.png' width="160">
            </td>
            <!-- <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mlaas_image'>
                  <video  width=100% height=100% muted autoplay loop>
                    <source src="images/mlaas_en.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                  </video>
                </div>
              </div>
              <script type="text/javascript">
                function mlaas_start() {
                  document.getElementById('mlaas_image').style.opacity = "1";
                }

                function mlaas_stop() {
                  document.getElementById('mlaas_image').style.opacity = "1";
                }
              </script>
            </td> -->
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="data/22-infocom-armol.pdf">
                <papertitle>Cost Effective MLaaS Federation: A Combinatorial Reinforcement Learning Approach</papertitle>
              </a>
              <br>
              <strong>Shuzhao Xie</strong>,
              Yuan Xue, 
							<a href="https://sites.ji.sjtu.edu.cn/yifei-zhu/">Yifei Zhu</a>,
              <a href="http://zwang.inflexionlab.org">Zhi Wang</a>
              <br>
              <em>INFOCOM</em>, 2022
              <br>
              <a href="data/22-infocom-armol.pdf">paper</a>
              /
              <a href="https://mmlabsigs.notion.site/Cost-Effective-MLaaS-Federation-A-Combinatorial-Reinforcement-Learning-Approach-fd27b02a403240f3b55ec26ad5ba00db">project page</a>
              /
              <!-- <a href="">video</a> -->
              <!-- / -->
              <a href="https://github.com/ShuzhaoXie/Armol">code</a>
              <p></p>
              <p>
              As naively using multiple ML APIs can lead to lower analytical accuracy and poor user experience,
                we employ reinforcement learning to select the optimal combination of MLaaSes, thus maximizing accuracy while minimizing cost. 
              </p>
            </td>
          </tr>
				
	
  <!-- <tr>
    <td style="padding:20px;width:25%;vertical-align:middle">
      <img src='images/openassl.png' width="160">
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <a href="https://shuzhaoxie.github.io">
        <papertitle>Open-World Recognition via Semi-Supervised Learning with Unseen Neuron</papertitle>
      </a>
      <br>
      Zeming Chen*,
      <strong>Shuzhao Xie*</strong>,
      Shiji Zhou,
			<a href="http://zwang.inflexionlab.org">Zhi Wang</a>,
			Tao Dai,
      Yuan Xue <br> (* equal contribution)
      <br>
			<em>In submission</em>
      <br>
      <p></p>
      <p>
      Discoverying unseen classes and classifying seen classes via an additional neuron at last layer under open-world recognition settings.
      </p>
    </td>
  </tr>

  <tr>
    <td style="padding:20px;width:25%;vertical-align:middle">
      <img src='images/mdls_v1.png' width="160">
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <a href="https://shuzhaoxie.github.io">
        <papertitle>A Manual-Free Label Alignment Approach for Multi-Dataset Abnormal Respiratory Sound Classification</papertitle>
      </a>
      <br>
      <strong>Shuzhao Xie</strong>,
      Yujie Yang,
      Yunpeng Bai,
      Nanyang Du,
      <a href="https://thuhcsi.github.io/zywu.html">Zhiyong Wu</a>,
			<a href="http://zwang.inflexionlab.org">Zhi Wang</a>
      <br>
			<em>In submission</em>
      <br>
      <p></p>
      <p>
      We reduce the NP-hard dataset-specific labels merging problem into a 0-1 integer linear programming problem, which is solvable in tolerable complexity.
      </p>
    </td>
  </tr> -->

  <!-- <tr>
    <td style="padding:20px;width:25%;vertical-align:middle">
      <img src='images/textir_v1.png' width="160">
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <a href="https://shuzhaoxie.github.io">
        <papertitle>TextIR: A Simple Framework for Text-based Editable Image Restoration</papertitle>
      </a>
      <br>
      Yunpeng Bai,
      <strong>Shuzhao Xie</strong>,
      Cairong Wang,
      <a href="http://xpixel.group/2010/01/20/chaodong.html">Chao Dong</a>,
      Chun Yuan,
			<a href="http://zwang.inflexionlab.org">Zhi Wang</a>
      <br>
			<em>In submission</em>
      <br>
      <p></p>
      <p>
        we design an effective framework that allows the user to control the restoration process of degraded images with text descriptions. This new framework provides a good starting point for the text-based image restoration task.
      </p>
    </td>
  </tr>
	 -->

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Industry Experience</heading>
            </td>
          </tr>
        </tbody>
      </table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/tencent_youtu_logo.jpg' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <strong>Tencent Youtu Lab</strong>, Shanghai, China
              <br>
              Research Intern
              <br>
              <i>Jan - May 2022</i>
              <br>
              <p>
                <li>Deployed Faster-RCNN into CPU environments with C++.</li>
                <li>Analyzed model performance under heterogeneous environments.</li>
              </p>
            </td>
          </tr>
        </tbody>
      </table>




        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Professional Service and Teaching</heading>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="20">
          
          <tbody>
					
          <table width="90%" align="center" border="0" cellpadding="0">
            <tbody>
              <tr>
                <td width="100%" valign="center">
                  <strong>Journal and Conference Reviewer</strong>
                  <li>CVPR: 2025</li>
                  <li>ACM MM: 2024</li>
                  <li>ICASSP: 2023 - 2025</li>  
                </td>
              </tr>
            </tbody>
          </table>

          <table width="90%" align="center" border="0" cellpadding="0">
            <tbody>
              <tr>
                <td width="100%" valign="center">
                  <strong>Teaching Assistant</strong>
                  <li>Big Data System (B), Tsinghua University, Fall 2021</li>  
                  <li>Distributed Machine Learning, Tsinghua University, Fall 2024</li>  
                </td>
              </tr>
            </tbody>
          </table>

        </tbody>
      </table>

      <table width="100%" align="center" border="0" cellpadding="20">
        <table width="90%" align="center" border="0" cellpadding="0">
          <tbody>
            <tr>
              <td width="100%" valign="center">
                <br>
                <p style="text-align:center;font-size:small;">
                  Template from <a href="https://jonbarron.info">Jon Barron</a>. Last updated in Jan 2025.
                </p>
              </td>
            </tr>
          </tbody>
        </table>
      </table>

      </td>
    </tr>
  </table>
</body>

</html>
